# HPC Quick Reference Card

## ğŸš€ Quick Commands

```bash
# Quick test (interactive)
./run_hpc.sh AAPL

# Batch job (recommended)
sbatch submit_hpc.sh

# Custom symbols
sbatch submit_hpc.sh "AAPL,MSFT,GOOG,TSLA,NVDA"

# Resume interrupted job
./run_pipeline.sh --hpc --resume output/hpc_batch_TIMESTAMP

# All 315 symbols
sbatch submit_hpc.sh "$(python3 -c 'from datasets import load_dataset; ds = load_dataset(\"usamaahmedsh/financial-markets-dataset-15y-train\", split=\"train\"); print(\",\".join(sorted(set(ds[\"ticker\"]))))')"
```

---

## ğŸ“Š Your HPC Resources

**Available modules:**
- Python: 3.10.5, 3.10.12, 3.13.8
- CUDA: 11.8, 12.2, 12.5, 12.8
- PyCUDA: 2019.1

**Loaded automatically by scripts**

---

## ğŸ¯ Expected Performance

| Symbols | Time (CPU) | Time (GPU) |
|---------|-----------|-----------|
| 1 | 30s | 10s |
| 10 | 5 min | 1-2 min |
| 50 | 25 min | 5-8 min |
| 315 (all) | 2.5 hrs | 30-45 min |

---

## ğŸ“ Output Structure

```
output/hpc_batch_20260215_143022/
â”œâ”€â”€ results.json              # Main output
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ processed_symbols.json
â”‚   â””â”€â”€ partial_results.json
â”œâ”€â”€ evaluation_report.html
â””â”€â”€ evaluation_metrics.json
```

---

## ğŸ” Monitoring

```bash
# Check queue
squeue -u $USER

# Watch output
tail -f output/slurm-*.out

# Job stats
seff <job_id>
```

---

## ğŸ“š Documentation

- Complete guide: `doc/HPC_GUIDE.md`
- Summary: `HPC_COMPLETE.md`
- Enhancements: `ENHANCEMENTS_COMPLETE.md`

---

## âœ… Features

- âœ… Auto-loads modules (Python, CUDA)
- âœ… Uses HF dataset (315 symbols, 15 years)
- âœ… Checkpoint/resume (fault-tolerant)
- âœ… Verbose progress (real-time tracking)
- âœ… Batch submission (SLURM ready)

**Run on your HPC cluster with one command!** ğŸš€
