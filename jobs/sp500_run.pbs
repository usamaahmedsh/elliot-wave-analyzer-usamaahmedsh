#!/bin/bash
#PBS -N elliott_sp500
#PBS -o logs/sp500.out
#PBS -e logs/sp500.err
#PBS -l nodes=1:ppn=16
#PBS -l mem=32gb
#PBS -l walltime=6:00:00
#PBS -q batch

# GPU configuration: 1 GPU with 12GB VRAM
#PBS -l nodes=1:ppn=16:gpus=1

# Load required modules (adjust for your HPC cluster)
module load python/3.11
module load cuda/12.1  # For NVIDIA GPU support

# Print job information
echo "======================================"
echo "Job ID: $PBS_JOBID"
echo "Job Name: $PBS_JOBNAME"
echo "Node: $(hostname)"
echo "CPUs: 16"
echo "Memory: 32GB"
echo "GPU: 12GB VRAM"
echo "Start time: $(date)"
echo "======================================"
echo ""

# Change to submission directory
cd $PBS_O_WORKDIR
echo "Working directory: $(pwd)"
echo ""

# Activate virtual environment
source venv/bin/activate
echo "Python: $(which python)"
echo "Python version: $(python --version)"
echo ""

# Check PyTorch and GPU availability
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'Device: {\"GPU\" if torch.cuda.is_available() else \"CPU\"}')"
echo ""

# Create necessary directories
mkdir -p output/checkpoints
mkdir -p logs
mkdir -p output/images

# Count symbols
SYMBOL_COUNT=$(wc -l < data/sp500_tickers.txt)
echo "Processing $SYMBOL_COUNT S&P 500 symbols"
echo ""

# Run the Elliott Wave pipeline
echo "Starting Elliott Wave pattern detection..."
echo "======================================"
python scripts/pipeline_run.py \
  --symbols "$(cat data/sp500_tickers.txt | tr '\n' ',')" \
  --output output/sp500_patterns.json \
  --checkpoint-dir output/checkpoints \
  --resume --verbose

# Check if pipeline succeeded
if [ $? -eq 0 ]; then
    echo ""
    echo "======================================"
    echo "Pipeline completed successfully!"
    echo "======================================"
    echo ""
    
    # Run data quality validation
    echo "Running data quality validation..."
    python tools/validate_data_quality.py \
      --input output/sp500_patterns.json \
      --output output/sp500_quality_report.txt
    
    # Print summary
    echo ""
    echo "======================================"
    echo "SUMMARY"
    echo "======================================"
    echo "Results saved to: output/sp500_patterns.json"
    echo "Quality report: output/sp500_quality_report.txt"
    echo ""
    
    # Show quality verdict
    if [ -f output/sp500_quality_report.txt ]; then
        echo "Data Quality:"
        grep -A 5 "Quality Verdict" output/sp500_quality_report.txt || echo "Check quality report for details"
    fi
    
    # Show file sizes
    echo ""
    echo "Output files:"
    ls -lh output/sp500_patterns.json
    ls -lh output/sp500_quality_report.txt
    
else
    echo ""
    echo "======================================"
    echo "Pipeline FAILED - check logs for errors"
    echo "======================================"
    echo ""
    echo "To resume from checkpoint:"
    echo "qsub jobs/sp500_run.pbs"
    exit 1
fi

echo ""
echo "======================================"
echo "Job completed at: $(date)"
echo "======================================"
